{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBGLoFC30LSe"
   },
   "source": [
    "<font color='black'> \n",
    "# Computational Statistics for Data Analysis\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wetd4VIP0LSk"
   },
   "source": [
    "# <div class=\"alert alert-error\"><strong><center><small>\"Statistics is the discipline of using data samples to support claims about populations.\"<small></center></strong> </div>\n",
    "\n",
    "In this notebook, we will get familiar with Descriptive statistics that comprise  concepts, terms, measures and tools that help to describe, show and summarize the data in a meaningful way. When analysing data, such as the price of flats renting per year, it is possible to use both descriptive and inferential statistics in order to analyse the results and draw some conclusions. We will discuss basic concepts,  terms and procedures, like mean, median, variance, correlation, etc.,  to explore, describe and summarize the given set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0c-fLTrC0LSm"
   },
   "source": [
    "Statistics is based on 2 main concepts:\n",
    "\n",
    "* A **population** is a collection of objects, items (“units”) about which information is sought.\n",
    "\n",
    "* A **sample** is a part of the population that is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FuGRnPu40LSo"
   },
   "source": [
    "<font color='black'> \n",
    "# 1 Descriptive Statistics.\n",
    "* 1.1 Getting data\n",
    "* 1.2 Data preparation\n",
    "* 1.3 Improving data as a pandas DataFrame\n",
    "* 1.4 Data cleaning \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZ7y01_80LSp"
   },
   "source": [
    "### \"Are the men more likely to become high income professionals i.e. to receive income bigger than 50K?\"\n",
    "\n",
    "Some people believe it is true, but **without data analysis** to support it, this claim is a case of **anecdotal evidence**:\n",
    "\n",
    "* There are a **small number of samples** (personal experience, friends, etc.).\n",
    "* There is a **selection bias**: most *believers* are interested in this claim because their first babies were late.\n",
    "* There is a **confirmation bias**: believers might be more likely to contribute data that confirm it.\n",
    "* Sources are **innaccurate**: personal stories are subject to memory deformations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3rtJF-B0LSr"
   },
   "source": [
    "## 1.1 Getting Data\n",
    "\n",
    "Let us consider a public database, called “Adult” dataset hosted on the UCI’s Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Adult), that contains approximately 32.000 observations about different financial parameters of US population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rpzuou3q0LSt"
   },
   "source": [
    "### 1.2 Data preparation\n",
    "\n",
    "One of the reasons we are using a general-purpose language such as Python rather than a stats language like R is that for many projects the *hard* part is preparing the data, not doing the analysis.\n",
    "\n",
    "The most common steps are:\n",
    "\n",
    "1. **Getting the data**. Data can be directly read from a file or it might be necessary to scrap the web.\n",
    "2. **Parsing the data**.  Of course, this depends on what format it is in: plain text, fixed columns, CSV, XML, HTML, etc.\n",
    "3. **Cleaning the data**.  Survey responses and other data files are almost always incomplete.  Sometimes there are multiple codes for things like, *not asked*, *did not know*, and *declined to answer*. And there are almost always errors. A simple strategy is to remove or ignore incomplete records.\n",
    "4. **Building data structures**. Once you read the data, you usually want to store it in a data structure that lends itself to the analysis you want to do.\n",
    "\n",
    "If the data fits into memory, building a data structure is usually the way to go.   If not, you could build a database, which is an out-of-memory data structure. Most databases provide a mapping from keys to values, so they are like dictionaries.\n",
    "\n",
    "Let us read the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMixJiWa0LS_"
   },
   "source": [
    "### 1.3 Importing data as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://drive.google.com/uc?id=1sjkFFbq6PoTIXQActsGmN3sf4DKhL2Rk', header=None, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "vtP_tMQj0LTA",
    "outputId": "497f1832-606e-42b2-f82f-34b9cef3092a"
   },
   "outputs": [],
   "source": [
    "df.columns = ['age', 'type_employer', 'fnlwgt', 'education', \n",
    "                \"education_num\",\"marital\", \"occupation\", \"relationship\", \"race\",\"sex\",\n",
    "                \"capital_gain\", \"capital_loss\", \"hr_per_week\",\"country\",\"income\"]\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CiJ-Pfn50LTF",
    "outputId": "18f62225-3c10-4be1-c1ec-1cecd3f9e5f9"
   },
   "outputs": [],
   "source": [
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J8Zm65q_0LTJ",
    "outputId": "f243f2c3-0dde-43e1-c9d7-2ff18c935262"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jF3jsUiI0LTM"
   },
   "source": [
    "Let's count the number of items per country:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "zA03kw9S0LTN",
    "outputId": "5d862e95-ba59-4321-84b7-be99af2bf2cc"
   },
   "outputs": [],
   "source": [
    "counts = df.groupby('country').size()\n",
    "\n",
    "print(counts) \n",
    "# also: df.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1088
    },
    "colab_type": "code",
    "id": "aC4K7mzX0LTR",
    "outputId": "9207f0d6-04e1-48a6-843e-051b2287adbc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts = df.groupby('age').size() # grouping by age\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KAFh3GTk0LTV",
    "outputId": "d1551f74-8ec8-417b-d2a7-6e487493fac8"
   },
   "outputs": [],
   "source": [
    "ml = df[(df.sex == 'Male')] # grouping by sex\n",
    "ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZTPtQKsi0LTZ",
    "outputId": "736b1543-6f38-45f3-f21e-70f02107cf34",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml1 = df[(df.sex == 'Male')&(df.income=='>50K')]\n",
    "ml1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NAu57sHN0LTd"
   },
   "source": [
    "Let's separate male from female according to the income. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iljsInDt0LTe",
    "outputId": "e20f7ef1-c940-4623-b15f-dfb1496d28e1"
   },
   "outputs": [],
   "source": [
    "fm =df[(df.sex == 'Female')]\n",
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qzizaWnG0LTi",
    "outputId": "16b291d3-5a59-40c0-ceb1-ecddfd58186d"
   },
   "outputs": [],
   "source": [
    "fm1 =df[(df.sex == 'Female')&(df.income=='>50K')]\n",
    "fm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "qpKq-E9m0LTo",
    "outputId": "0bcd2e18-ad33-4cc7-cd68-b2baa1cac041"
   },
   "outputs": [],
   "source": [
    "df1=df[(df.income=='>50K')]\n",
    "\n",
    "print('The rate of people with high income is: ', int(len(df1)/float(len(df))*100), '%.') \n",
    "print('The rate of men with high income is: ', int(len(ml1)/float(len(ml))*100), '%.') \n",
    "print('The rate of women with high income is: ', int(len(fm1)/float(len(fm))*100), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CWe8Mpw_0LTu"
   },
   "source": [
    "### 1.4 Data Cleaning\n",
    "\n",
    "The most common steps are:\n",
    "\n",
    "+ **Sample the data**. If the amount of raw data is huge, processing all of them may require an extensive amount of processing power which may not be practical.  In this case, it is quite common to sample the input data to reduce the size of data that need to be processed.\n",
    "\n",
    "+ **Impute missing data**. It is quite common that some of the input records are incomplete in the sense that certain fields are missing or have input error.  In a typical tabular data format, we need to validate each record contains the same number of fields and each field contains the data type we expect. In case the record has some fields missing, we have the following choices: \n",
    "    - Discard the whole record if it is incomplete; \n",
    "    - Infer the missing value based on the data from other records.  A common approach is to fill the missing data with the average, or the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wXbYKUmq0LTv"
   },
   "source": [
    "+ **Normalize numeric value**. Normalize data is about transforming numeric data into a uniform range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LqV3zc2T0LTw"
   },
   "source": [
    "+ **Reduce dimensionality**. High dimensionality can be a problem for some machine learning methods.  There are two ways to reduce the number of input features.  One is about $removing$ $irrelevant$ input variables, another one is about $removing$ $redundant$ input variables.\n",
    "+ **Add derived features**. In some cases, we may need to compute additional attributes from existing attributes (f.e. converting a geo-location to a zip code, or converting the age to an age group).\n",
    "+ **Discretize numeric value into categories**. Discretize data is about cutting a continuous value into ranges and assigning the numeric with the corresponding bucket of the range it falls on.  For numeric attribute, a common way to generalize it is to discretize it into ranges, which can be either constant width (variable height/frequency) or variable width (constant height).\n",
    "+ **Binarize categorical attributes**. Certain machine learning models only take binary input (or numeric input).  In this case, we need to convert categorical attribute into multiple binary attributes, while each binary attribute corresponds to a particular value of the category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lqtPsuQ0LTy"
   },
   "source": [
    "+ **Select, combine, aggregate data**. Designing the form of training data is the most important part of the whole predictive modeling exercise because the accuracy largely depends on whether the input features are structured in an appropriate form that provide strong signals to the learning algorithm. Rather than using the raw data as it is, it is quite common that multiple pieces of raw data need to be combined together, or aggregating multiple raw data records along some dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzSPT-Td0LTy"
   },
   "source": [
    "## 2 Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcGligmG0LTz"
   },
   "source": [
    "### 2.1 Summarizing the data: \n",
    "#### 2.1.1 Sample Mean \n",
    "\n",
    "If you have a sample of $n$ values, $x_i$, the **sample mean** is the sum of the values divided by the number of values:\n",
    "\n",
    "$$ \\mu = \\frac{1}{n} \\sum_i x_i$$\n",
    "\n",
    "The **mean** is the most basic and important summary statistic. It describes the central tendency of a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRGcHzzT0LT0"
   },
   "source": [
    "There is a small difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xSEcxQal0LT2",
    "outputId": "4d3cdb4d-e558-4376-d714-0dd98a10ed87"
   },
   "outputs": [],
   "source": [
    "print('The average age of men is: ', ml['age'].mean(), '.') \n",
    "print('The average age of women is: ', fm['age'].mean(), '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "92knH9o-0LT4"
   },
   "source": [
    "This difference in sample means can be considered a first evidence of our hypothesis!\n",
    "\n",
    "\n",
    "**Comment:** *Later, we will work with both concepts: the population mean and the sample mean. Do not confuse them! Remember, the first one is the mean of samples taken from the population and the second one is the mean of the whole population.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mE4imo6U0LT4",
    "outputId": "c76e3e8a-6a5e-4329-e18c-5f052714c2ad"
   },
   "outputs": [],
   "source": [
    "print('The average age of high-income men is: ', ml1['age'].mean(), '.') \n",
    "print('The average age of high-income women is: ', fm1['age'].mean(), '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCvT1oF40LT7"
   },
   "source": [
    "#### 2.1.2 Sample Variance\n",
    "\n",
    "Usually, mean is not a sufficient descriptor of the data, we can do a little better with two numbers: mean and **variance**:\n",
    "\n",
    "$$ \\sigma^2 = \\frac{1}{n} \\sum_i (x_i - \\mu)^2 $$\n",
    "\n",
    "**Variance** $\\sigma^2$ describes the *spread* of data. The term $(x_i - \\mu)$ is called the *deviation from the mean*, so variance is the mean squared deviation.\n",
    "\n",
    "The square root of variance, $\\sigma$, is called the **standard deviation**. We define standard deviation because variance is hard to interpret (in the case the units are grams, the variance is in grams squared). Let's get the basic statistics for our example data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Y2Rqx-9q0LT7",
    "outputId": "183b5b2a-1030-472f-ee91-bc71794daa9d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ml_mu = ml['age'].mean()\n",
    "fm_mu = fm['age'].mean()\n",
    "ml_var = ml['age'].var()\n",
    "fm_var = fm['age'].var()\n",
    "ml_std = ml['age'].std()\n",
    "fm_std = fm['age'].std()\n",
    "print('Statistics of age for men: mu:', ml_mu, 'var:', ml_var, 'std:', ml_std)\n",
    "print('Statistics of age for women: mu:', fm_mu, 'var:', fm_var, 'std:', fm_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "I72UcDVO0LUA",
    "outputId": "69e3d15e-0d98-45d3-e9fc-c6f62274808d"
   },
   "outputs": [],
   "source": [
    "ml_mu_hr = ml['hr_per_week'].mean()\n",
    "fm_mu_hr = fm['hr_per_week'].mean()\n",
    "ml_var_hr = ml['hr_per_week'].var()\n",
    "fm_var_hr = fm['hr_per_week'].var()\n",
    "ml_std_hr = ml['hr_per_week'].std()\n",
    "fm_std_hr = fm['hr_per_week'].std()\n",
    "print('Statistics of hours per week for men: mu:', ml_mu_hr, 'var:', ml_var_hr, 'std:', ml_std_hr)\n",
    "print('Statistics  of hours per week for women: mu:', fm_mu_hr, 'var:', fm_var_hr, 'std:', fm_std_hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "st_9aTQu0LUC"
   },
   "source": [
    "#### 2.1.3 Sample Median\n",
    "\n",
    "The statistical median is an order statistic that gives the *middle* value of a sample. It is a value more robust to ouliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Sna_CIg40LUC",
    "outputId": "813ad5eb-8583-4f25-d001-f3920c793c27"
   },
   "outputs": [],
   "source": [
    "ml_median= ml['age'].median()\n",
    "fm_median= fm['age'].median()\n",
    "print(\"Median age per men and women: \", ml_median, fm_median)\n",
    "\n",
    "ml_median_age= ml1['age'].median()\n",
    "fm_median_age= fm1['age'].median()\n",
    "print(\"Median age per men and women with high-income: \", ml_median_age, fm_median_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LekgUvdZ0LUE",
    "outputId": "c0a009ad-5e6a-437a-cd67-b93438f325c2"
   },
   "outputs": [],
   "source": [
    "ml_median_hr= ml['hr_per_week'].median()\n",
    "fm_median_hr= fm['hr_per_week'].median()\n",
    "print(\"Median hours per week per men and women: \", ml_median_hr, fm_median_hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okHZuCLw0LUH"
   },
   "source": [
    "#### 2.1.4 Summarizing the data: Quantiles & Percentiles\n",
    "\n",
    "Order the sample $\\{ x_i \\}$, then find $x_p$ so that it divides the data into two parts where:\n",
    "\n",
    "+ a fraction $p$ of the data values are less than or equal to $x_p$ and\n",
    "+ the remaining fraction $(1 − p)$ are greater than $x_p$.\n",
    "\n",
    "That value $x_p$ is the pth-quantile, or 100×pth percentile.\n",
    "\n",
    "**5-number summary**: $x_{min}, Q_1, Q_2, Q_3, x_{max}$, where $Q_1$ is the 25×pth percentile,\n",
    "$Q_2$ is the 50×pth percentile and $Q_3$ is the 75×pth percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmLjWSnD0LUH"
   },
   "source": [
    "### 2.2 Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0EoOoy90LUI"
   },
   "source": [
    "The most common representation of a distribution is a **histogram**, which is a graph that shows the frequency of each value. Let us visualize the histogram for the age of the male and female populations in our example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "7Vsk7hZo0LUI",
    "outputId": "afc3c540-84a9-4c88-9c85-72b57799c615"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ml_age=ml['age']\n",
    "ml_age.hist(density=0, histtype='stepfilled', bins=20)\n",
    "\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('Male samples',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "666sC8h80LUL",
    "outputId": "0f569bf1-3749-4529-f1d8-6595ee07ae9c"
   },
   "outputs": [],
   "source": [
    "fm_age=fm['age']\n",
    "\n",
    "fm_age.hist(density=0, histtype='stepfilled', bins=10)\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('Female samples',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dyeArFMw0LUN"
   },
   "source": [
    "Let's compare both populations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "5v1Z117W0LUN",
    "outputId": "1649820e-f87f-484a-b9d9-a55e396c8a77"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fm_age.hist(density=0, histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\n",
    "ml_age.hist(density=0, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75), bins=10)\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('Samples',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "WRXsdSlH0LUP",
    "outputId": "af573edc-3572-4211-ebcb-0d124caee59e"
   },
   "outputs": [],
   "source": [
    "fm_age.hist(density=1, histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\n",
    "ml_age.hist(density=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75), bins=10)\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('PMF',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjOXQUyM0LUR"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEbSD-Lp0LUS"
   },
   "source": [
    "## 2.3 Data Distributions\n",
    "\n",
    "Summarizing can be dangerous: very different data can be described by the same statistics. It must be validated by inspecting the data.\n",
    "\n",
    "We can look at the **data distribution**, which describes how often (frequency) each value appears.\n",
    "\n",
    "\n",
    "We can normalize the frequencies of the histogram by dividing/normalizing by $n$, the number of samples. The normalized histogram is called **Probability Mass Function (PMF)**.\n",
    "\n",
    "Let's visualize and compare the PMF of male and female age in our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "S314gaQ40LUT",
    "outputId": "badc44b1-53fe-4685-b2c2-86ca9af60d96"
   },
   "outputs": [],
   "source": [
    "ml_age.hist(density=1, histtype='stepfilled', bins=20)\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('Probability',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "kJ-gyrcP0LUV",
    "outputId": "0e4e46e2-a5ae-4700-aea9-bfdc314184f6"
   },
   "outputs": [],
   "source": [
    "fm_age.hist(density=1, histtype='stepfilled', bins=20)\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('Probability',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pn3tqAC60LUW"
   },
   "source": [
    "The **cumulative distribution function (CDF)**, or just distribution function, describes the probability that a real-valued random variable X with a given probability distribution will be found to have a value less than or equal to x. For our example, the CDFs will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "E4BbqORZ0LUX",
    "outputId": "199d3d6c-0f8c-430a-ce53-1c2c15985405"
   },
   "outputs": [],
   "source": [
    "ml_age.hist(density=1, histtype='step', cumulative=True, linewidth=3.5, bins=20)\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('CDF',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "xcMue3BU0LUZ",
    "outputId": "d2394e51-d4ed-4010-8919-0a67cf968dbe"
   },
   "outputs": [],
   "source": [
    "fm_age.hist(density=1, histtype='step', cumulative=True, linewidth=3.5, bins=20)\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('CDF',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "G0aKF5aq0LUa",
    "outputId": "9eacb659-15d2-4b70-e0ab-2f36f5976705"
   },
   "outputs": [],
   "source": [
    "ml_age.hist(bins=10, density=1, histtype='stepfilled', alpha=.5)   # default number of bins = 10\n",
    "fm_age.hist(bins=10, density=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75))\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('Probability',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "S-vBV-m70LUd",
    "outputId": "0d9a2b73-044f-414d-b5a9-e9cc82e84789"
   },
   "outputs": [],
   "source": [
    "ml_age.hist(density=1, histtype='step', cumulative=True,  linewidth=3.5, bins=20)\n",
    "fm_age.hist(density=1, histtype='step', cumulative=True,  linewidth=3.5, bins=20, color=sns.desaturate(\"indianred\", .75))\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('CDF',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D4qGUV0Y0LUf",
    "outputId": "6425a3f3-f8fb-42c9-9293-48511551a4ca"
   },
   "outputs": [],
   "source": [
    "print(\"The mean sample difference is \", ml_age.mean() - fm_age.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_5t03P50LUh"
   },
   "source": [
    "## 2.4 Outliers\n",
    "\n",
    "**Ouliers** are data samples with a value that is far from the central tendency.\n",
    "\n",
    "We can find outliers by:\n",
    "\n",
    "+ Computing samples that are *far* from the median.\n",
    "+ Computing samples whose value *exceeds the mean* by 2 or 3 standard deviations.\n",
    "\n",
    "This expression will return a series of boolean values that you can then index the series by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e7PJKLWB0LUh",
    "outputId": "acfdef09-9693-49ef-fe5e-c994db8031b5"
   },
   "outputs": [],
   "source": [
    "df['age'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hkf45_3J0LUj"
   },
   "source": [
    "Let's see how many outliers we can detect in our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WarEyxWd0LUk",
    "outputId": "6dc5a862-2ec0-46a4-e054-3f573006ea37"
   },
   "outputs": [],
   "source": [
    "len(df[(df.income == '>50K') & (df['age'] < df['age'].median() - 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "62nBaecr0LUn",
    "outputId": "39f2ee89-170b-4163-db7f-b6222f8411f8"
   },
   "outputs": [],
   "source": [
    "len(df[(df.income == '>50K') & (df['age'] > df['age'].median() + 35)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gv_RQw_F0LUp"
   },
   "source": [
    "If we think that outliers correspond to errors, an option is to trim the data by discarting the highest and lowest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.income=='>50K')]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N066l2GI0LUq",
    "outputId": "bd923f5b-2d03-444a-e5db-63e6c78fe30a"
   },
   "outputs": [],
   "source": [
    "df2 = df1.drop(df1.index[(df1['age']>df['age'].median() + 35) | (df1['age']<df['age'].median() - 15)])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cr3iHBC00LUt"
   },
   "outputs": [],
   "source": [
    "ml1_age=ml1['age']\n",
    "fm1_age=fm1['age']\n",
    "\n",
    "ml2_age = ml1_age.drop(ml1_age.index[(ml1_age > df['age'].median() + 35) | (ml1_age < df['age'].median() - 15)])\n",
    "fm2_age = fm1_age.drop(fm1_age.index[(fm1_age > df['age'].median() + 35) | (fm1_age < df['age'].median() - 15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LdoKI5QH0LUv",
    "outputId": "2b02f4a0-1bfc-4c15-8588-082496e058b0"
   },
   "outputs": [],
   "source": [
    "mu2ml = ml2_age.mean()\n",
    "std2ml = ml2_age.std()\n",
    "md2ml = ml2_age.median()\n",
    "# Computing the mean, std, median, min and max for the high-income male population\n",
    "print(\"Men statistics: Mean:\", mu2ml, \"Std:\", std2ml, \"Median:\", md2ml, \"Min:\", ml2_age.min(), \"Max:\", ml2_age.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w58fRrqB0LUx",
    "outputId": "d22e2e54-c9fa-4081-c560-b7390da18be7"
   },
   "outputs": [],
   "source": [
    "mu3ml = fm2_age.mean()\n",
    "std3ml = fm2_age.std()\n",
    "md3ml = fm2_age.median()\n",
    "# Computing the mean, std, median, min and max for the high-income female population\n",
    "print(\"Women statistics: Mean:\", mu3ml, \"Std:\", std3ml, \"Median:\", md3ml, \"Min:\", fm2_age.min(), \"Max:\", fm2_age.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xI7wrx6r0LU2",
    "outputId": "d62bbce2-4042-4b81-9895-62b3ba72350f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('The mean difference with outliers is: %.2f.' % (ml_age.mean() - fm_age.mean()))\n",
    "print(\"The mean difference without outliers is: %.2f.\" % (ml2_age.mean() - fm2_age.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXGGHOs_0LU4"
   },
   "source": [
    "Let's compare visually the age distributions before and after removing the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "xxhLFgS60LU4",
    "outputId": "a9644719-fb43-4f3f-b357-e1b551f10d98"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13.4,5))\n",
    "\n",
    "df.age[(df.income == '>50K')].plot(alpha=.25, color='blue')\n",
    "df2.age[(df2.income == '>50K')].plot(alpha=.45,color='red')\n",
    "\n",
    "plt.ylabel('Age')\n",
    "plt.xlabel('Samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNZ3hYmg0LU6"
   },
   "source": [
    "Let's see what is happening near the mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJIytwoH0LU6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "countx,divisionx = np.histogram(ml2_age, density=True) \n",
    "county,divisiony = np.histogram(fm2_age, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "ttYYEoQN0LU8",
    "outputId": "b920bbf6-fbd5-4e1a-aff0-b354169e9ae5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val = [(divisionx[i]+divisionx[i+1])/2 for i in range(len(divisionx)-1)]\n",
    "plt.plot(val, countx-county, 'o-') \n",
    "plt.title('Differences in promoting men vs. women')\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('Differences',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5W6wAgN0LU-"
   },
   "source": [
    "There is still some evidence for our hypothesis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "RHpUuKSC0LU-",
    "outputId": "494fce9a-7829-4bbb-d2ab-99b0e4dbe796"
   },
   "outputs": [],
   "source": [
    "print(\"Remember:\\nWe have the following mean values for men, women and the difference:\\nOriginally: \", ml_age.mean(), fm_age.mean(),  ml_age.mean()- fm_age.mean())  # The difference between the mean values of male and female populations.\n",
    "print(\"For high-income: \", ml1_age.mean(), fm1_age.mean(), ml1_age.mean()- fm1_age.mean()) # The difference between the mean values of male and female populations.\n",
    "print(\"After cleaning: \", ml2_age.mean(), fm2_age.mean(), ml2_age.mean()- fm2_age.mean()) # The difference between the mean values of male and female populations.\n",
    "\n",
    "print(\"\\nThe same for the median:\")\n",
    "print(ml_age.median(), fm_age.median(), ml_age.median() - fm_age.median()) # The difference between the mean values of male and female populations.\n",
    "print(ml1_age.median(), fm1_age.median(), ml1_age.median() - fm1_age.median()) # The difference between the mean values of male and female populations.\n",
    "print(ml2_age.median(), fm2_age.median(), ml2_age.median() - fm2_age.median()) , # The difference between the mean values of male and female populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUGMu2NP0LVA"
   },
   "source": [
    "### 2.5 Measuring asymmetry (optional).\n",
    "\n",
    "**Skewness** is a statistic that measures the asymmetry of set of $n$ data samples $x_i$:\n",
    "\n",
    "$$ g_1 = \\frac{1}{n}\\frac{\\sum_i (x_i - \\mu)^3 }{\\sigma^3 }$$\n",
    "\n",
    "The numerator is the mean cubed deviation and the denominator the cubed standard deviation.\n",
    "\n",
    "Negative deviation indicates that the distribution \"skews left\" (it extends farther to the left than to the right).\n",
    "\n",
    "**Skewness** can be affected by outliers!!! A simpler alternative is to look at the relationship between mean ($\\mu$) and median ($\\mu_{\\frac{1}{2}}$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KfJFc9gY0LVB",
    "outputId": "ba2b2ddc-3b06-47d5-bba2-5d5947cb5118",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def skewness(x):\n",
    "    res=0\n",
    "    m=x.mean()\n",
    "    s=x.std()\n",
    "    for i in x:\n",
    "        res+=(i-m)*(i-m)*(i-m)\n",
    "    res/=(len(x)*s*s*s)\n",
    "    return res\n",
    "\n",
    "print(\"The skewness of the male population is:\", skewness(ml2_age))\n",
    "print(\"The skewness of the female population is:\", skewness(fm2_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZcf5uiq0LVD"
   },
   "source": [
    "**2.6 Pearson's median skewness coefficient** is a more robust alternative:\n",
    "\n",
    "$$ g_p = \\frac{3(\\mu - \\mu_{\\frac{1}{2}})}{\\sigma} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYsKJvzq0LVD"
   },
   "source": [
    "**Exercise**: Write a function to compute $g_1$ and $g_p$ of the pregnancy length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Vx6ifwlP0LVD",
    "outputId": "c015be7e-1982-485e-bc74-408dcde96c06"
   },
   "outputs": [],
   "source": [
    "def pearson(x):\n",
    "    return 3*(x.mean()-x.median())/x.std()\n",
    "\n",
    "print(\"The Pearson's coefficient of the male population is:\", pearson(ml2_age))\n",
    "print(\"The Pearson's coefficient of the female population is:\", pearson(fm2_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UyQ4U6Vc0LVF"
   },
   "source": [
    "## 2.6 Relative Risk\n",
    "\n",
    "Let's say that a person is \"early\" promoted if he/she is promoted before the age of 41, \"on time\" if he/she is promoted of age 41, 42, 43 or 44, and \"late\" promoted if he/she is ascended to get income bigger than 50K after being 44 years old. Let us compute the probability of being early, on time and late promoted for men and women:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uqMMpKnI0LVF",
    "outputId": "a807fd08-1955-4cce-f83d-3bdcf441ca59"
   },
   "outputs": [],
   "source": [
    "#ml1 = df[(df.sex == 'Male')&(df.income=='>50K')]\n",
    "\n",
    "ml2 = ml1.drop(ml1.index[(ml1['age'] > df['age'].median() + 35) | (ml1['age'] < df['age'].median() - 15)])\n",
    "fm2 = fm1.drop(fm1.index[(fm1['age'] > df['age'].median() + 35) | (fm1['age'] < df['age'].median() - 15)])\n",
    "\n",
    "print(ml2.shape, fm2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "hBNyi_ax0LVH",
    "outputId": "2457bebc-934a-4a49-afdc-f02dbada651a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Men grouped in 3 categories:\")\n",
    "print(\"Young:\",int(round(100*len(ml2_age[ml2_age<=41])/float(len(ml2_age.index)))),\"%.\")\n",
    "print(\"Elder:\", int(round(100*len(ml2_age[ml2_age >=44])/float(len(ml2_age.index)))),\"%.\")\n",
    "print(\"Average age:\", int(round(100*len(ml2_age[(ml2_age>41) & (ml2_age< 44)])/float(len(ml2_age.index)))),\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "fcHuCUCn0LVJ",
    "outputId": "1d6c49aa-fee3-4475-e1b2-4f706ce59a47"
   },
   "outputs": [],
   "source": [
    "print(\"Women grouped in 3 categories:\")\n",
    "print(\"Young:\",int(round(100*len(fm2_age[fm2_age <=41])/float(len(fm2_age.index)))),\"%.\")\n",
    "print(\"Elder:\", int(round(100*len(fm2_age[fm2_age >=44])/float(len(fm2_age.index)))),\"%.\")\n",
    "print(\"Average age:\", int(round(100*len(fm2_age[(fm2_age>41) & (fm2_age< 44)])/float(len(fm2_age.index)))),\"%.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5nqX7fy0LVK"
   },
   "source": [
    "The **relative risk** is the ratio of two probabilities. In order to get the relative risk \\cite{Downey} of early promotion, we need to consider the  fraction of both probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p6UE17Ib0LVL",
    "outputId": "d608f8f2-e415-486c-9cbc-2c989455d2f3"
   },
   "outputs": [],
   "source": [
    "print(\"The male mean:\", ml2_age.mean())\n",
    "print(\"The female mean:\", fm2_age.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hjacH-HZ0LVN",
    "outputId": "aed7c18d-9bee-4fe1-c397-0bf305ef0bf4"
   },
   "outputs": [],
   "source": [
    "ml2_young = len(ml2_age[(ml2_age<41)])/float(len(ml2_age.index))\n",
    "fm2_young  = len(fm2_age[(fm2_age<41)])/float(len(fm2_age.index))\n",
    "print(\"The relative risk of female early promotion is: \", 100*(1-ml2_young/fm2_young))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-sxJbRON0LVO"
   },
   "source": [
    "That means that women are 21% more likely to get high gains before 41 years than men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8FsBLmrF0LVP",
    "outputId": "4ee9ea09-3f40-424f-e401-2620b104e723"
   },
   "outputs": [],
   "source": [
    "ml2_elder = len(ml2_age[(ml2_age>44)])/float(len(ml2_age.index))\n",
    "fm2_elder  = len(fm2_age[(fm2_age>44)])/float(len(fm2_age.index))\n",
    "print(\"The relative risk of male late promotion is: \", 100*(ml2_elder/fm2_elder-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Topek2K0LVQ"
   },
   "source": [
    "That means that men are 29% more likely to get high gains after 44 years than women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHz7Jznl0LVQ"
   },
   "source": [
    "### Discussions.\n",
    "\n",
    "After exploring the data, we obtained some apparent effects that seem to support our first assumption:\n",
    "\n",
    "+ **Data description:** The mean age for ascending male professionals is 44 years old while for female professionals it is 41 years.\n",
    "\n",
    "+ **Relative risk:** Female professionals are 21%  more likely to be ascended before 41 years of age, while men are 29% more likely to be ascended being at least 45 years old.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WC4PQDy0LVR"
   },
   "source": [
    "## 3 Continous distributions\n",
    "\n",
    "So far, we have built **empirical distributions** (which represent the distributions of values in a sample), based on observations, but many real problems are well approximated by fitting **continous distributions functions (CDF)**. \n",
    "\n",
    "They are called in this way because the distribution is described by an analytical continous function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAB2Ul0s0LVR"
   },
   "source": [
    "### 3.1 The exponential distribution\n",
    "\n",
    "The CDF of the exponential distribution is:\n",
    "\n",
    "$$ CDF(x) = 1 -  \\exp^{- \\lambda x}$$ \n",
    "\n",
    "And its PDF is:\n",
    "\n",
    "$$ PDF(x) = \\lambda \\exp^{- \\lambda x}$$\n",
    "\n",
    "The parameter $\\lambda$ determines the shape of the distribution, the mean of the distribution is $1/\\lambda$ and its variance is $1/\\lambda^2$. The median is $ln(2)/\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "FfEnIvEi0LVS",
    "outputId": "c90876ba-6f9f-4ca8-cd9f-2735e191c4c6"
   },
   "outputs": [],
   "source": [
    "l = 3\n",
    "x=np.arange(0,2.5,0.1)\n",
    "y= 1 - np.exp(-l*x)\n",
    "plt.plot(x,y,'-')\n",
    "plt.title('Exponential CDF: $\\lambda$ =%.2f' % l ,fontsize=15)\n",
    "plt.xlabel('x',fontsize=15)\n",
    "plt.ylabel('CDF',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "C6G7CJaW0LVT",
    "outputId": "dbc9329c-f449-4a1f-f9bd-a9f7a6445438"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "l = 3\n",
    "x=np.arange(0,2.5,0.1)\n",
    "y= l * np.exp(-l*x)\n",
    "plt.plot(x,y,'-')\n",
    "plt.title('Exponential PDF: $\\lambda$ =%.2f' % l, fontsize=15)\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('PDF', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-EOmavJ0LVU"
   },
   "source": [
    "There are a lot of real world events that can be described with this distribution.\n",
    "* The time until a radioactive particle decays,\n",
    "* The time it takes before your next telephone call,\n",
    "* The time until default (on payment to company debt holders) in reduced form credit risk modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L--Fl0_30LVU"
   },
   "source": [
    "The random variable $X$ of the lifelengths of some batteries is associated with a probability density function of the form:\n",
    "\n",
    "$$ PDF(x) = \\frac{1}{4} \\exp^{- \\frac{x}{4}}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "aKirCfow0LVV",
    "outputId": "592ead4c-6d2a-4dcc-bcaf-b41a680ca4d9"
   },
   "outputs": [],
   "source": [
    "l = 0.25\n",
    "x=np.arange(0,25,0.1)\n",
    "y= l * np.exp(-l*x)\n",
    "plt.plot(x,y,'-')\n",
    "plt.title('Exponential: $\\lambda$ =%.2f' % l ,fontsize=15)\n",
    "plt.xlabel('x',fontsize=15)\n",
    "plt.ylabel('PDF',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6lyVhrA20LVX"
   },
   "source": [
    "### 3.2 The normal distribution\n",
    "\n",
    "The **normal, or Gaussian distribution** is the most used one because it describes a lot of phenomena and because it is amenable for analysis. \n",
    "\n",
    "Its CDF has no closed-form expression and its more common representation is the PDF:\n",
    "\n",
    "$$ PDF(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left(-\\frac{(x-\\mu)^2}{2 \\sigma^2} \\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "hoiVPZca0LVX",
    "outputId": "555fcefa-8c8b-4110-d11f-fdf35eebe850"
   },
   "outputs": [],
   "source": [
    "u=6 # mean\n",
    "s=2 # standard deviation\n",
    "x=np.arange(0,15,0.1)\n",
    "y=(1/(np.sqrt(2*np.pi*s*s)))*np.exp(-(((x-u)**2)/(2*s*s)))\n",
    "plt.plot(x,y,'-')\n",
    "plt.title('Gaussian PDF: $\\mu$=%.1f, $\\sigma$=%.1f' % (u,s),fontsize=15)\n",
    "plt.xlabel('x',fontsize=15)\n",
    "plt.ylabel('Probability density',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0sumoo3q0LVa"
   },
   "source": [
    "Examples:\n",
    "    * Measures of size of living tissue (length, height, skin area, weight);\n",
    "    * The length of inert appendages (hair, claws, nails, teeth) of biological specimens, in the direction of growth; presumably the thickness of tree bark also falls under this category;\n",
    "    * Certain physiological measurements, such as blood pressure of adult humans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9K2MNsq0LVa"
   },
   "source": [
    "### 3.3 Central Limit Theorem\n",
    "\n",
    "The normal distribution is also important, because it is involved in the Central Limit Theorem:\n",
    "\n",
    "> Take the mean of $n$ random samples from ANY arbitrary distribution with a $well$ $defined$ standard deviation $\\sigma$ and mean $\\mu$. As $n$ gets bigger the **distribution of the sample mean** will always converge to a Gaussian (normal) distribution with mean $\\mu$ and standard deviation $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "Colloquially speaking, the theorem states the distribution of an average tends to be normal, even when the distribution from which the average is computed is decidedly non-normal. This explains the ubiquity of the Gaussian distribution in science and statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XN131Zpo0LVa"
   },
   "source": [
    "#### Example: Uniform Distribution\n",
    "\n",
    "The uniform distribution is obviously non-normal.  Let's call it the $parent$ $distribution$.\n",
    "\n",
    "To compute an average, two samples are drawn ($n=2$), at random, from the parent distribution and averaged. Then another sample of two is drawn and another value of the average computed.  This process is repeated, over and over, and averages of two are computed.  \n",
    "\n",
    "Repeatedly taking more elements ($n = 3,4...$) from the parent distribution, and computing the averages, produces a normal probability density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "SW1DhgjH0LVa",
    "outputId": "f550aeed-829c-437a-fcae-464c15dd8910"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, sharey=True, squeeze=True, figsize=(14, 5))\n",
    "x = np.linspace(0, 1, 100)\n",
    "for i in range(4):\n",
    "    f = np.mean(np.random.random((10000, i+1)), 1)\n",
    "    m, s = np.mean(f), np.std(f, ddof=1)\n",
    "    fn = (1/(s*np.sqrt(2*np.pi)))*np.exp(-(x-m)**2/(2*s**2))  # normal pdf            \n",
    "    ax[i].hist(f, 40, density=True, color=[0, 0.2, .8, .6]) \n",
    "    ax[i].set_title('n=%d' %(i+1))\n",
    "    ax[i].plot(x, fn, color=[1, 0, 0, .6], linewidth=5)\n",
    "plt.suptitle('Demonstration of the central limit theorem for a uniform distribution', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RbqdZqOv0LVc"
   },
   "source": [
    "## 3.4 Kernel density estimates\n",
    "\n",
    "In some instances, we may not be interested in the parameters of a particular distribution of data, but just a **continous representation** of the data at hand. In this case, we can estimate the distribution non-parametrically (i.e. making no assumptions about the form of the underlying distribution) using kernel density estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "xWswrmRQ0LVc",
    "outputId": "d30b5f6b-6c10-47b7-d14c-b0c0dcbeac38"
   },
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm\n",
    "\n",
    "# Some random data\n",
    "y = np.random.random(15) * 10\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "x1 = np.random.normal(-1, 2, 15) # parameters: (loc=0.0, scale=1.0, size=None)\n",
    "x2 = np.random.normal(6, 3, 10)\n",
    "y = np.r_[x1, x2] # r_ Translates slice objects to concatenation along the first axis.\n",
    "x = np.linspace(min(y), max(y), 100)\n",
    "\n",
    "\n",
    "# Smoothing parameter\n",
    "s = 0.4\n",
    "\n",
    "# Calculate the kernels\n",
    "kernels = np.transpose([norm.pdf(x, yi, s) for yi in y])\n",
    "\n",
    "plt.plot(x, kernels, 'k:')\n",
    "plt.plot(x, kernels.sum(1), 'r')\n",
    "plt.plot(y, np.zeros(len(y)), 'go', ms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "UZOidBTs0LVe",
    "outputId": "19ad371c-0478-4a39-deb3-7acdaf2a194c"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kde\n",
    "\n",
    "x1 = np.random.normal(-1, 0.5, 15) # parameters: (loc=0.0, scale=1.0, size=None)\n",
    "x2 = np.random.normal(6, 1, 10)\n",
    "y = np.r_[x1, x2] # r_ Translates slice objects to concatenation along the first axis.\n",
    "x = np.linspace(min(y), max(y), 100)\n",
    "\n",
    "s = 0.4 # Smoothing parameter\n",
    "\n",
    "kernels = np.transpose([norm.pdf(x, yi, s) for yi in y]) # Calculate the kernels\n",
    "density = kde.gaussian_kde(y)\n",
    "\n",
    "plt.plot(x, kernels, 'k:')\n",
    "plt.plot(x, kernels.sum(1), 'r')\n",
    "plt.plot(y, np.zeros(len(y)), 'bo', ms=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "ia-ffkU50LVh",
    "outputId": "aee07ef1-9935-4643-952d-1e5d21b14336"
   },
   "outputs": [],
   "source": [
    "xgrid = np.linspace(x.min(), x.max(), 200)\n",
    "plt.hist(y, bins=28, density=True)\n",
    "plt.plot(xgrid, density(xgrid), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49Pk3AHg0LVi"
   },
   "source": [
    "SciPy implements a Gaussian KDE that automatically chooses an appropriate bandwidth. Let's create a bi-modal distribution of data that is not easily summarized by a parametric distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qw47BlFj0LVi"
   },
   "outputs": [],
   "source": [
    "# Create a bi-modal distribution with a mixture of Normals.\n",
    "x1 = np.random.normal(-1, 2, 15) # parameters: (loc=0.0, scale=1.0, size=None)\n",
    "x2 = np.random.normal(6, 3, 10)\n",
    "\n",
    "# Append by row\n",
    "x = np.r_[x1, x2] # r_ Translates slice objects to concatenation along the first axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "cBamsdUt0LVk",
    "outputId": "bb571ee6-b9a2-4e21-b17b-5f26523c81e5"
   },
   "outputs": [],
   "source": [
    "plt.hist(x, bins=18, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "lLKVHElV0LVm",
    "outputId": "ffb21727-97c1-4654-b6f0-50daab784186"
   },
   "outputs": [],
   "source": [
    "density = kde.gaussian_kde(x)\n",
    "xgrid = np.linspace(x.min(), x.max(), 200)\n",
    "plt.hist(x, bins=18,density=True)\n",
    "plt.plot(xgrid, density(xgrid), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4iOtPCI0LVo"
   },
   "source": [
    "## 4 Estimation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "Ox9KOJnq0LVo",
    "outputId": "618e4966-7bcf-4ea2-b162-020d3b8414d4"
   },
   "outputs": [],
   "source": [
    "x = np.random.normal(0.0, 1.0, 10000)\n",
    "a = plt.hist(x,50,density='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAkUwhbV0LVp"
   },
   "source": [
    "\n",
    "**Definition:** *Estimation* is the process of inferring the parameters (e.g. mean) of a distribution from a statistic of samples drown from a population.\n",
    "\n",
    "For example: What is the estimated mean $\\hat{\\mu}$ of the following normal data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VfLRT_O0LVq"
   },
   "source": [
    "We can use our definition of empirical mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gxlxE7mO0LVq",
    "outputId": "8facd583-af3f-44da-a5d6-360655b7476e"
   },
   "outputs": [],
   "source": [
    "print('The empirical mean of the sample is ', x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgADfZ9x0LVr"
   },
   "source": [
    "### 4.1 Sample mean\n",
    "\n",
    "+ The process is called **estimation** and the statistic we used **estimator**.\n",
    "\n",
    "+ The median is also an estimator (more robust to outliers). \n",
    "\n",
    "+ \"Is median better than sample mean?\" is a question with at least two different answers. We can use two different objectives to answer this question: the minimization of error or the maximization to get the right answer. \n",
    "\n",
    "+ If there are no outliers, we can use the **sample mean** to minimize **mean squared error** (where $m$ is the number of times you play the estimation game, not the size of the sample!):\n",
    "\n",
    "$$ MSE = \\frac{1}{m} \\sum(\\hat{\\mu} - \\mu)^2$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rWKO7psn0LVr",
    "outputId": "4bdccfd2-213e-4ce9-aa0b-424aceb3e186"
   },
   "outputs": [],
   "source": [
    "NTs=200\n",
    "mu=0.0\n",
    "var=1.0\n",
    "err = 0.0\n",
    "NPs=1000\n",
    "for i in range(NTs):\n",
    "    x = np.random.normal(mu, var, NPs)\n",
    "    err += (x.mean()-mu)**2\n",
    "\n",
    "print('MSE: ', err/NTs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YRpt80I0LVs"
   },
   "source": [
    "### 4.2 Variance\n",
    "\n",
    "We can also estimate the variance with:\n",
    "\n",
    "$$ \\hat{\\sigma}^2 = \\frac{1}{n} \\sum_i (x_i - \\mu)^2 $$\n",
    "\n",
    "This estimator works for large samples, but it is biased for small samples. We can use this one:\n",
    "\n",
    "$$ \\hat{\\sigma}^2_{n-1} = \\frac{1}{n-1} \\sum_i (x_i - \\mu)^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HZZaM_V0LVs"
   },
   "source": [
    "### 4.3 Other concepts: Standard scores\n",
    "\n",
    "$$ z_i = \\frac{x_i - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgduZ33F0LVt"
   },
   "source": [
    "This measure is dimensionless and its distribution has mean 0 and variance 1.\n",
    "\n",
    "It inherits the \"shape\" of $X$: if it is normally distributed, so is $Z$. If $X$ is skewed, so is $Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xz4EOr_o0LVt"
   },
   "source": [
    "### 4.4 Covariance\n",
    "\n",
    "**Covariance** is a measure of the tendency of two variables to vary together. \n",
    "\n",
    "If we have two series $X$ and $Y$ with $X=\\{x_i\\}$ and $Y=\\{y_i\\}$, and they vary together, their deviations $x_i - \\mu_X$ and $y_i - \\mu_Y$ tend to have the same sign.\n",
    "\n",
    "If we multiply them together, the product is positive, when the deviations have the same sign, and negative, when they have the opposite sign. So adding up the products gives a measure of the tendency to vary together.\n",
    "\n",
    "Covariance is the mean of the products:\n",
    "\n",
    "$$ Cov(X,Y) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu_X)*(y_i - \\mu_Y), $$\n",
    "\n",
    "where $n$ is the length of the two series.\n",
    "\n",
    "It is a measure that is difficult to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ahc0c6CJ0LVt",
    "outputId": "5c3ba3f1-9b5d-40f5-915c-f17dcf84d148",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Cov(X, Y):\n",
    "    def _get_dvis(V):\n",
    "        return [v - np.mean(V) for v in V]\n",
    "    dxis = _get_dvis(X)\n",
    "    dyis = _get_dvis(Y)\n",
    "    return np.sum([x * y for x, y in zip(dxis, dyis)])/len(X)\n",
    "\n",
    "\n",
    "X = [5, -1, 3.3, 2.7, 12.2]\n",
    "X = np.array(X)\n",
    "Y = [10, 12, 8, 9, 11]\n",
    "Y = np.array(Y)\n",
    "\n",
    "print(\"Cov(X, X) = %.2f\" % Cov(X, X))\n",
    "print(\"Var(X) = %.2f\" % np.var(X))\n",
    "print(\"Cov(X, Y) = %.2f\" % Cov(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJX5swlB0LVu"
   },
   "source": [
    "Let us create some examples of positive and negative correlations like those showing the relations of stock market with respect to the economic growth or the gasoline prices with respect to the world oil production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QKToOBg60LVv"
   },
   "outputs": [],
   "source": [
    "X=np.array([[1,9],[3, 2], [5,3],[5.5,4],[6,4],[6.5,4],[7,3.5],[7.5,3.8],[8,4],\n",
    "            [8.5,4],[9,4.5],[9.5,7],[10,9],[10.5,11],[11,11.5],[11.5,12],[12,12],[12.5,12],[13,10]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "A2jRspos0LVv",
    "outputId": "e765d4f8-be30-40cc-ecba-660ecc215f26"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X[:,0],X[:,1],color='b',s=120, linewidths=2,zorder=10)\n",
    "plt.xlabel('Economic growth(T)',fontsize=15)\n",
    "plt.ylabel('Stock market returns(T)',fontsize=15)\n",
    "plt.gcf().set_size_inches((20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "JbgaxWSQ0LVy",
    "outputId": "b4d19b32-cafe-4654-f282-e2284047dc62"
   },
   "outputs": [],
   "source": [
    "X=np.array([[1,8],[2, 7], [3,6],[4,8],[5,8],[6,7],[7,7],[8,5],[9,5],[10,6],[11,4],[12,5],[13,3],[14,2],[15,2],[16,1]])\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X[:,0],X[:,1],color='b',s=120, linewidths=2,zorder=10)\n",
    "plt.xlabel('World Oil Production(T)',fontsize=15)\n",
    "plt.ylabel('Gasoline prices(T)',fontsize=15)\n",
    "plt.gcf().set_size_inches((20,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9V59ghE0LVz"
   },
   "source": [
    "### 4.5 Pearson's Correlation\n",
    "\n",
    "Shell we take into account the variance? An alternative is to divide the deviations by $\\sigma$, which yields standard scores, and compute the product of standard scores:\n",
    "\n",
    "$$ p_i = \\frac{(x_i - \\mu_X)}{\\sigma_X} \\frac{(y_i - \\mu_Y)}{\\sigma_Y} $$\n",
    " \n",
    "The mean of these products is:\n",
    "\n",
    "$$ \\rho = \\frac{1}{n} \\sum p_i = \\frac{1}{n} \\sum  \\frac{(x_i - \\mu_X)}{\\sigma_X} \\frac{(y_i - \\mu_Y)}{\\sigma_Y}  $$\n",
    "\n",
    "Or we can rewrite $\\rho$ by factoring out $\\sigma_X$ and $\\sigma_Y$:\n",
    "\n",
    "$$ \\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}$$\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pofEda7o0LVz",
    "outputId": "dc263aba-75f5-41bd-9864-c4a6d12ab338"
   },
   "outputs": [],
   "source": [
    "def Corr(X, Y):\n",
    "    assert len(X) == len(Y)\n",
    "    return Cov(X, Y) / np.prod([np.std(V) for V in [X, Y]])\n",
    "\n",
    "print(\"Corr(X, X) = %.5f\" % Corr(X[:,0], X[:,0]))\n",
    "\n",
    "Y=np.random.random(len(X[:,0]))\n",
    "\n",
    "print(\"Corr(X, Y) = %.5f\" % Corr(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hErIY-x20LV1"
   },
   "source": [
    "When $\\rho = 0$, we cannot say that there is no relationship between the variables!\n",
    "\n",
    "Pearson's coefficient only measures **linear** correlations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnBec_4j0LV1"
   },
   "source": [
    "### 4.6 Spearman’s rank correlation\n",
    "\n",
    "Pearson’s correlation works well if the relationship between variables is linear and if the variables are roughly normal. But it is not robust in the presence of **outliers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1rxe2Ay0LV2"
   },
   "source": [
    "Spearman’s rank correlation is an alternative that mitigates the effect of outliers and skewed distributions. To compute Spearman’s correlation, we have to compute the rank of each value, which is its index in the sorted sample. \n",
    "\n",
    "For example, in the sample {7, 1, 2, 5} the rank of the value 5 is 3, because it appears third if we sort the elements. \n",
    "\n",
    "Then, we compute the Pearson’s correlation, **but for the ranks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "lJn8kpMo0LV2",
    "outputId": "c79e3298-eba3-47df-de93-7a679b783026"
   },
   "outputs": [],
   "source": [
    "def list2rank(l):\n",
    "    #l is a list of numbers\n",
    "    # returns a list of 1-based index; mean when multiple instances\n",
    "    return [np.mean([i+1 for i, sorted_el in enumerate(sorted(l)) if sorted_el == el]) for el in l]\n",
    "\n",
    "l = [7, 1, 2, 5]\n",
    "print(\"ranks: \", list2rank(l))\n",
    "\n",
    "def spearmanRank(X, Y):\n",
    "    # X and Y are same-length lists\n",
    "    print(list2rank(X)) \n",
    "    print(list2rank(Y))\n",
    "    return Corr(list2rank(X), list2rank(Y))\n",
    "\n",
    "X = [10, 20, 30, 40, 1000]\n",
    "Y = [-70, -1000, -50, -10, -20]\n",
    "plt.plot(X,'ro')\n",
    "plt.plot(Y,'go')\n",
    "\n",
    "print(\"Pearson rank coefficient: %.2f\" % Corr(X, Y))\n",
    "print(\"Spearman rank coefficient: %.2f\" % spearmanRank(X, Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZMZubfb0LV3"
   },
   "source": [
    "**Exercise:** Obtain for the Anscombe's quartet [2] given in the figures bellow, the different estimators (mean, variance, covariance for each pair, Pearson's correlation and Spearman's rank correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "colab_type": "code",
    "id": "MufK_dnX0LV3",
    "outputId": "3fd40af1-99b7-485f-b7b0-94b1b1ab3679"
   },
   "outputs": [],
   "source": [
    "X=np.array([[10.0, 8.04, 10.0, 9.14, 10.0, 7.46, 8.0, 6.58],\n",
    "[8.0, 6.95, 8.0, 8.14, 8.0, 6.77, 8.0, 5.76],\n",
    "[13.0,7.58,13.0,8.74,13.0,12.74,8.0,7.71],\n",
    "[9.0,8.81,9.0,8.77,9.0,7.11,8.0,8.84],\n",
    "[11.0,8.33,11.0,9.26,11.0,7.81,8.0,8.47],\n",
    "[14.0,9.96,14.0,8.10,14.0,8.84,8.0,7.04],\n",
    "[6.0,7.24,6.0,6.13,6.0,6.08,8.0,5.25],\n",
    "[4.0,4.26,4.0,3.10,4.0,5.39,19.0,12.50],\n",
    "[12.0,10.84,12.0,9.13,12.0,8.15,8.0,5.56],\n",
    "[7.0,4.82,7.0,7.26,7.0,6.42,8.0,7.91],\n",
    "[5.0,5.68,5.0,4.74,5.0,5.73,8.0,6.89]])\n",
    "\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.scatter(X[:,0],X[:,1],color='r',s=120, linewidths=2,zorder=10)\n",
    "plt.xlabel('x1',fontsize=15)\n",
    "plt.ylabel('y1',fontsize=15)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(X[:,2],X[:,3],color='r',s=120, linewidths=2,zorder=10)\n",
    "plt.xlabel('x1',fontsize=15)\n",
    "plt.ylabel('y1',fontsize=15)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.scatter(X[:,4],X[:,5],color='r',s=120, linewidths=2,zorder=10)\n",
    "plt.xlabel('x1',fontsize=15)\n",
    "plt.ylabel('y1',fontsize=15)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.scatter(X[:,6],X[:,7],color='r',s=120, linewidths=2,zorder=10)\n",
    "plt.xlabel('x1',fontsize=15)\n",
    "plt.ylabel('y1',fontsize=15)\n",
    "plt.gcf().set_size_inches((10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N869CajB0LV5"
   },
   "source": [
    "### 5. Main reference\n",
    "[1] *Think Stats: Probability and Statistics for Programmers*, by Allen B. Downey, published by O'Reilly Media.\n",
    "http://www.greenteapress.com/thinkstats/\n",
    "\n",
    "[2] Anscombe's quartet, https://en.wikipedia.org/wiki/Anscombe%27s_quartet"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-Descriptive-Statistics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
